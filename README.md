## International AI and AV strategy, policy and risk
AI and governance work with MIT Media Lab, Harvard Berkman Klein Center, Harvard Law School, Harvard Kennedy School and private government clients including developing best practices for AI and ethics in government, universities and industry and advising local and regional governments internationally on AI and AV strategy, risk and policy. 

AI and governance affiliate researcher, [MIT Media Lab](https://www.media.mit.edu/people/ggreene/overview/) and [Harvard Berkman Klein Center](https://cyber.harvard.edu/people/gretchen-greene)

AI strategy, policy and risk advisor/consultant

- BC AI Governance Joint Convening. Facilitating cross agency collaboration and developing AI best practices across British Columbia, Canada

- ["Potholes, Rats and Criminals: A Framework for AI Ethical Risk"](https://datasmart.ash.harvard.edu/news/article/potholes-rats-and-criminals), Data-Smart City Solutions (read in ~8,000 cities each month), Harvard Kennedy School

- ["Buying your First AI: or Never Trust a Used Algorithm Salesman"](https://medium.com/berkman-klein-center/buying-your-first-ai-136cd2e6dd2), Harvard Berkman Klein Center

- "AV scenario issue spotting workshop" and "AI for government benefits issue spotting workshop", codesigned and facilitated workshops at AG Tech Forum on AI, national convening of state attorneys general at Harvard Law School, 2018

- "When algorithms are against the law: lessons from case law and the Constitution for city CDOs", presentation to Civics Analytics Network's (CAN's), U.S. national convening of large city CDOs, Harvard Kennedy School, 2018 

- Advised multinational corporations and early stage startups at BKC, MIT, and Princeton Workshop on AI and Ethics, 2018

- Designed surveys on AI for the U.S. National League of Cities (NLC) and National Association of Counties (NACo)

- Founding member of [Techtopia](http://techtopia.harvard.edu/), Harvard initiative on ethics and governance of emerging digital technologies

## Machine learning, computer vision, artificial intelligence and autonomous vehicles
### Dragon Paint: GANs, art and extreme data augmentation
An ongoing project exploring the limits of data augmentation and art generation, using expressive augmentation and GANs for generating style consistent cartoons characters and group variation from extremely small original data sets.

- [DragonPaint: Rule based bootstrapping for small data with an application to cartoon coloring. In Proceedings of the Fourth International Conference on Predictive Applications and APIs, volume 82, pages 1-9, Boston, MA, 2017](https://www.papis.io/proceedings)

- [An Infinite Parade of Giraffes: Expressive Augmentation and Complexity Layers for Cartoon Drawing](https://arxiv.org/pdf/1811.07023.pdf), PAPIs Europe 2018, arVix 1811.07023 

- "GANs and Gaussian Filters for Design Propagation and Variation Across Groups of Cartoon Characters from a Single Example"

### EqualAIs: Facial recognition adversarial attacks
MIT Media Lab/Harvard Berkman Center AI and Governance Assembly project, [EqualAIs](http://equalais.media.mit.edu/). Our team developed a white box, substitution model facial recognition adversarial attack prototype, successful against the major APIs, filed a FOIA with partners ACLU and a private law firm, presented at numerous conferences and published a collection of open source code and resources on facial recognition and adversarial attacks.

- "EqualAIs: Facial recognition adversarial attacks and policy", Google Brain, Cambridge, MA, 2018

- "Facial recognition: adversarial attacks, policy and choice", PAPIs Global, Boston, MA, 2018"

- "How machine vision fails: Adversarial attacks, AV accidents and other problems", REWORK Deep Learning for Robotics and AI in Industrial Automation Summits", SF, CA, 2018

### Working with startups in transportation, fashion, healthcare...
- Decision making AI for autonomous vehicles 

- Computer vision for QR codes in wearables 

- Machine learning for drug delivery system 

- Computer vision tools testing and documentation

### Bio
K. G. Greene is an AI and governance affiliate researcher at MIT Media Lab and Harvard Berkman Klein Center for Internet and Society. Greene's work on AI and governance has included developing best practices for AI and ethics in government, universities and industry and advising local and regional governments internationally on government AI strategy, risk and policy. A Yale trained lawyer, computer vision scientist and former U.S. national lab mathematician, Greene has written decision making algorithms for autonomous car navigation, terrorist tracking and Hollywood animation. Greene has been interviewed by the Economist and Forbes China and has published in machine learning, policy and science journals.
